{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cy0JfqNT8cRw"
   },
   "source": [
    "#Google Colaboratory\n",
    "Google Colaboratory, 줄여서 Colab은 인공지능 프로그래밍을 편하고 interactive 하게 코딩을 할 수 있도록 도와줍니다!\n",
    "\n",
    "Colab은 브라우저에서 Python 코드를 작성할 수 있고 실행할 수 있습니다.\n",
    "*   구성 필요 없음\n",
    "*   GPU 무료 액세스\n",
    "*   간편한 공유\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvvyM22ARYUQ"
   },
   "source": [
    "\n",
    "\n",
    "## <strong>시작하기</strong>\n",
    "\n",
    "지금 읽고 계신 문서는 정적 웹페이지가 아니라 코드를 작성하고 실행할 수 있는 대화형 환경인 <strong>Colab 메모장</strong>입니다.\n",
    "\n",
    "예를 들어 다음은 값을 계산하여 변수로 저장하고 결과를 출력하는 간단한 Python 스크립트가 포함된 <strong>코드 셀</strong>입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp8BVkl08bQY"
   },
   "outputs": [],
   "source": [
    "seconds_in_a_day = 24 * 60 * 60\n",
    "seconds_in_a_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4TAe2vNRGjL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7K2I2a1dQxpN"
   },
   "source": [
    "위 셀의 코드를 실행하려면 셀을 클릭하여 선택한 후 코드 왼쪽의 실행 버튼을 누르거나 단축키 'Command/Ctrl+Enter'를 사용하세요. 셀을 클릭하면 코드 수정을 바로 시작할 수 있습니다.\n",
    "\n",
    "특정 셀에서 정의한 변수를 나중에 다른 셀에서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZ5S1KJUQ6_x"
   },
   "outputs": [],
   "source": [
    "seconds_in_a_week = 7 * seconds_in_a_day\n",
    "seconds_in_a_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHqovgMWRHJ6"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Colab을 통해 인기 있는 Python 라이브러리를 최대한 활용하여 데이터를 분석하고 시각화할 수 있습니다. 아래 코드 셀에서는 <strong>numpy</strong>를 사용하여 임의의 데이터를 생성하고 <strong>matplotlib</strong>으로 이를 시각화합니다. 셀을 클릭하면 코드 수정을 바로 시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRjacfCWRL7K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ys = 200 + np.random.randn(100)\n",
    "x = [x for x in range(len(ys))]\n",
    "\n",
    "plt.plot(x, ys, '-')\n",
    "plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)\n",
    "\n",
    "plt.title(\"Sample Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVrXSOaYTAY2"
   },
   "source": [
    "#Environment\n",
    "강화학습은 환경이 정의하는 문제를 해결하는 방법론입니다. 따라서 문제를 정의하는 환경을 잘 구성하는 것이 무엇보다 중요합니다.\n",
    "\n",
    "환경은 크게 3가지 요소인 State, Action, Reward를 중심으로 생각합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyr2hpVVRivQ"
   },
   "source": [
    "#OpenAI Gym\n",
    "OpenAI는 알파고, 알파스타 등등 강화학습으로 유명한 AI들을 개발한 기업입니다. 홈페이지에서는 다양한 강화학습 알고리즘이나 환경들을 제공하므로, 참고하기 좋습니다.\n",
    "\n",
    "OpenAI Gym은 강화학습 환경의 표준적인 Baseline을 제공합니다. 또한 여러가지 sample 환경들을 제공하고, 이외에도 다양한 환경들이 gym style에 맟춰서 개발되므로 이에 맟춰서 코드를 작성한다면 알고리즘의 동작을 확인할 때 많은 환경에서 실험할 수 있습니다.\n",
    "\n",
    "https://gym.openai.com/\n",
    "\n",
    "OpenAI Gym 설치는 아래 코드로 간단하게 진행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTvAg_3bUdKK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /home/elsa/anaconda3/envs/grid/lib/python3.6/site-packages (0.17.2)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/elsa/anaconda3/envs/grid/lib/python3.6/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/elsa/anaconda3/envs/grid/lib/python3.6/site-packages (from gym) (1.19.0)\n",
      "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /home/elsa/anaconda3/envs/grid/lib/python3.6/site-packages (from gym) (1.3.0)\n",
      "Requirement already satisfied: scipy in /home/elsa/anaconda3/envs/grid/lib/python3.6/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: future in /home/elsa/anaconda3/envs/grid/lib/python3.6/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XoUnqI7UtjX"
   },
   "source": [
    "이번 실습은 Gym Taxi 환경에서 진행합니다. 다음 코드는 Taxi-v3 환경에서 랜덤한 액션을 하는 에이전트를 보여주는 코드입니다.\n",
    "\n",
    "먼저 환경 오브젝트를 생성합니다. gym.make(환경이름)을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6L0zi1jYIJr"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGYE3I_xYQmk"
   },
   "source": [
    "환경을 초기화하고 첫 state를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuhe02lOYbHq"
   },
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFraYDmHYbwo"
   },
   "source": [
    "env.render은 환경을 visualize 해주는 함수입니다.\n",
    "\n",
    "env.action_space는 환경의 action과 관련된 정보를 가진 오브젝트입니다. sample 함수로 랜덤한 action을 고릅니다.\n",
    "\n",
    "env.step(action)은 해당 action을 환경에서 실행하고, state, reward, done, info값을 받아옵니다.\n",
    "State는 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBn2IBVsYIsp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4H-b6zhXRPA"
   },
   "outputs": [],
   "source": [
    "\n",
    "for _ in range(1000):\n",
    "  env.render()\n",
    "  action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "  state, reward, done, info = env.step(action)\n",
    "\n",
    "  if done:\n",
    "    state = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNwitqAvVClm"
   },
   "source": [
    "#Gym Taxi\n",
    "Taxi 환경은 grid world에서 출발지에서 승객을 태우고, 도착지에 승객을 내리는 것이 목표입니다. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnOuJH3PQ+BIWvk/JU131/",
   "name": "강화학습실습.ipynb의 사본",
   "provenance": [
    {
     "file_id": "1AYW1AxLRZN0R_Xg-3xuvwXNBpYiaWOzT",
     "timestamp": 1596963070163
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
